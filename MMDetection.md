---
created: 2022-04-22T01:58:04+08:00
modified: 2022-05-03T18:20:49+08:00
---

# MMDetection/MMD

model zoo:

https://github.com/Zhongdao/Towards-Realtime-MOT/blob/master/DATASET_ZOO.md

mmd auto tracking:

https://github.com/errno-mmd/mmdmatic/blob/master/setup.bat

if we can re-trace the action/expression done by vtubers, we can monetize those "highlight cuts".

you can firstly find points in datasets and then generate mmd videos, and then create trainset. you can also generate pose from raw video and then create dataset.

found occasionally when browsing MMD, but found this with so many stars, which is an instance detection/segmentation library.
https://github.com/open-mmlab/mmdetection

while rendering mmd can be done with mmd viewer like https://github.com/benikabocha/saba or could use renderer like blender or unity. we must bake physics before dancing.

found other dedicated renderer for mmd, with bullet physics:
https://github.com/jinfagang/mmc

found interesting repo of poetry composing:
https://github.com/jinfagang/tensorflow_poems

mediapipe/paddlevideo alike:
https://pypi.org/project/alfred-py/

three.js has multiple loaders:
https://github.com/mrdoob/three.js/tree/dev/examples/js/loaders
https://github.com/hanakla/three-mmd-loader

render MMD using saba lib:
https://github.com/WLiangJun/MMD-Desktop-mascot

https://github.com/miu200521358/expose_mmd/fork

music based dance:
https://github.com/DeepVTuber/DanceNet3D
https://github.com/ColbyZhuang/music2dance_DanceNet
https://github.com/caijianfei/Music2Dance

characters:
https://www.mixamo.com/#/?page=1&type=Character
